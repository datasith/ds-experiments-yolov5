{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c05be40-e8bc-4c30-959e-847017d8e801",
   "metadata": {},
   "source": [
    "## Prepare the SKU110K Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9fd6b7-07be-49e6-8626-6c04fd5f9e1f",
   "metadata": {},
   "source": [
    "#### Download and extract the SKU110K dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed08866c-3c19-48f9-993d-0bb8dcb1b611",
   "metadata": {},
   "source": [
    "This step will vary by Users' preference. If nothing else, it serves to keep track of the URL where to find the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5fbfa03-a3ca-43a8-a3c0-d94c8a94713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://trax-geometry.s3.amazonaws.com/cvpr_challenge/SKU110K_fixed.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d04d45c2-918e-4b6f-9680-4a4dd1c967ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xvf SKU110K_fixed.tar.gz > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858346d-08e1-49a8-a503-6f4b2d93fc33",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4a3dadeb-d323-4af8-93d9-4d5660d263ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79caf28-c9eb-4fa4-a155-feb58466a5db",
   "metadata": {},
   "source": [
    "#### Set up the dataset's local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bdc8facc-50f6-4beb-af17-e4d5cd6eace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sku_dataset_folder  = '/Users/f0z01ld/Work/datasets' # os.getcwd()\n",
    "sku_dataset_dirname = 'SKU110K_fixed'\n",
    "path_images         = Path(sku_dataset_folder) / sku_dataset_dirname / 'images'\n",
    "path_annotations    = Path(sku_dataset_folder) / sku_dataset_dirname / 'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d62cc8b2-4164-424a-876e-b8cf187a6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls $path_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b80d4f-94b2-4041-87ff-b12ed88da744",
   "metadata": {},
   "source": [
    "#### Re-organize files into test, train, and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3da85e39-02bc-43a0-a88d-fb5fc089c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_to_channel = {\n",
    "    \"train\": \"train\",\n",
    "    \"val\": \"validation\",\n",
    "    \"test\": \"test\",\n",
    "}\n",
    "\n",
    "assert path_images.exists(), f\"{path_images} not found\"\n",
    "\n",
    "for channel_name in prefix_to_channel.values():\n",
    "    if not (path_images.parent / channel_name).exists():\n",
    "        (path_images.parent / channel_name).mkdir()\n",
    "\n",
    "for path_img in path_images.iterdir():\n",
    "    for prefix in prefix_to_channel:\n",
    "        if path_img.name.startswith(prefix):\n",
    "            path_img.replace(\n",
    "                path_images.parent / prefix_to_channel[prefix] / path_img.name\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6acbc1-1503-4d93-97c4-a0eab9526eef",
   "metadata": {},
   "source": [
    "#### Remove corrupted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f33787bb-987a-4ae8-98d8-a42f7ab4f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRUPTED_IMAGES = {\n",
    "    \"train\": (\"train_4222.jpg\", \"train_5822.jpg\", \"train_882.jpg\", \"train_924.jpg\"),\n",
    "    \"validation\": tuple(),\n",
    "    \"test\": (\"test_274.jpg\", \"test_2924.jpg\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a10df4e3-c45e-4246-b520-2ff00a9951bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_4222.jpg removed from channel train \n",
      "train_5822.jpg removed from channel train \n",
      "train_882.jpg removed from channel train \n",
      "train_924.jpg removed from channel train \n",
      "test_274.jpg removed from channel test \n",
      "test_2924.jpg removed from channel test \n"
     ]
    }
   ],
   "source": [
    "for channel_name in prefix_to_channel.values():\n",
    "    for img_name in CORRUPTED_IMAGES[channel_name]:\n",
    "        try:\n",
    "            (path_images.parent / channel_name / img_name).unlink()\n",
    "            print(f\"{img_name} removed from channel {channel_name} \")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{img_name} not in channel {channel_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55dfce98-debb-464a-811a-f27c835a0f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train images = 8215\n",
      "Number of validation images = 588\n",
      "Number of test images = 2934\n"
     ]
    }
   ],
   "source": [
    "# Expected output:\n",
    "# Number of train images = 8215\n",
    "# Number of validation images = 588\n",
    "# Number of test images = 2934\n",
    "for channel_name in prefix_to_channel.values():\n",
    "    print(\n",
    "        f\"Number of {channel_name} images = {sum(1 for x in (path_images.parent / channel_name).glob('*.jpg'))}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cce703c1-f3d0-40af-a1b8-07d8d15db22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rmdir(path_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b26ae8c-53bf-45f8-8e1e-3e20b0056b5a",
   "metadata": {},
   "source": [
    "#### Reformat label (annotations) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d508224-7b71-4ad5-a9b6-3ab3d6027e3c",
   "metadata": {},
   "source": [
    "Taking the snipped of code from `./yolov5/data/SKU-110K.yaml` and modifying it for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0fdd8de1-385e-4725-8b3b-020bd0cb5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov5_dataset_folder = os.getcwd()\n",
    "yolov5_sku_dataset_dirname = 'SKU110K_fixed'\n",
    "local_path_annotations = Path(yolov5_dataset_folder) / yolov5_sku_dataset_dirname / 'labels'\n",
    "local_path_images = Path(yolov5_dataset_folder) / yolov5_sku_dataset_dirname / 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "664a2e80-f04b-4c0d-8ff2-bcc07548c3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/f0z01ld/Work/object-detection-yolov5/datasets/SKU110K_fixed/labels')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_path_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "25470a53-d9d2-4235-adf3-fd52ceea8f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $local_path_annotations $local_path_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582eaf2-1f75-4a2a-bdd7-f5afb379a355",
   "metadata": {},
   "source": [
    "The original format of the `SKU110K` dataset is:\n",
    "\n",
    "`'image', 'x1', 'y1', 'x2', 'y2', 'class', 'image_width', 'image_height'`\n",
    "\n",
    "We need to convert it to `YOLO` format, which is:\n",
    "\n",
    "`'class', 'x1', 'y1', 'x2', 'y2'`\n",
    "\n",
    "We also need to normalize the bounding box coordinates as expected by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "adbefb81-8296-47ce-9d38-b22b0af09728",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = 'image', 'x1', 'y1', 'x2', 'y2', 'class', 'image_width', 'image_height'\n",
    "\n",
    "annotation_files =  path_annotations.glob('*.csv')\n",
    "for file in annotation_files:\n",
    "    data = pd.read_csv(file, names=names)  # annotations\n",
    "    prefix = file.name.split('_')[-1].replace('.csv','')\n",
    "    out_labels_dir = local_path_annotations / prefix\n",
    "    out_images_dir = local_path_images / prefix\n",
    "\n",
    "    isExist = os.path.exists(out_labels_dir)\n",
    "    if not isExist:\n",
    "        os.mkdir(out_labels_dir)\n",
    "\n",
    "    isExist = os.path.exists(out_images_dir)\n",
    "    if not isExist:\n",
    "        os.mkdir(out_images_dir)\n",
    "    \n",
    "    for idx_row, row in data.iterrows():\n",
    "        out_labels_file = out_labels_dir / f'{prefix}_{idx_row}.txt'\n",
    "        images_file = path_images.parent / prefix / f'{prefix}_{idx_row}.jpg'\n",
    "        out_images_file = out_images_dir / f'{prefix}_{idx_row}.jpg'\n",
    "        object_class = 0 # only one class for this dataset\n",
    "        w  = row['image_width']\n",
    "        h  = row['image_height']\n",
    "        x1 = row['x1'] / w\n",
    "        y1 = row['y1'] / h\n",
    "        x2 = row['x2'] / w\n",
    "        y2 = row['y2'] / h\n",
    "\n",
    "        try:\n",
    "            _ = shutil.copy2(images_file, out_images_file)\n",
    "        except:\n",
    "            continue # fails are due to image file not existing for the corresponding label\n",
    "        \n",
    "        with open(out_labels_file,'w') as f:\n",
    "            f.write(f'{object_class} {x1} {y1} {x2} {y2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aafcbca-9c14-4d5d-b25e-12f13d17dc86",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
