{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c05be40-e8bc-4c30-959e-847017d8e801",
   "metadata": {},
   "source": [
    "## SKU110K Dataset to YOLOv5 Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2ee634-201f-4bb2-ac29-27e57d25dd3c",
   "metadata": {},
   "source": [
    "\n",
    "> `Date: 09/28/2021`\n",
    "<br/>\n",
    "> `Author: @datasith`\n",
    "<br/>\n",
    "> `Last Modified:`\n",
    "<br/>\n",
    "> `/* name - date */`\n",
    "<br/>\n",
    "> `License: https://github.com/datasith/datasith/blob/main/licenses/LICENSE.nsfw`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9fd6b7-07be-49e6-8626-6c04fd5f9e1f",
   "metadata": {},
   "source": [
    "#### Download and extract the SKU110K dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed08866c-3c19-48f9-993d-0bb8dcb1b611",
   "metadata": {},
   "source": [
    "This step will vary by Users' preference. If nothing else, it serves to keep track of the URL where to find the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fbfa03-a3ca-43a8-a3c0-d94c8a94713e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://trax-geometry.s3.amazonaws.com/cvpr_challenge/SKU110K_fixed.tar.gz -P Path_to_directory_where_the_images_should_be_downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04d45c2-918e-4b6f-9680-4a4dd1c967ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !tar -xvf SKU110K_fixed.tar.gz > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858346d-08e1-49a8-a503-6f4b2d93fc33",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3dadeb-d323-4af8-93d9-4d5660d263ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79caf28-c9eb-4fa4-a155-feb58466a5db",
   "metadata": {},
   "source": [
    "#### Set up the dataset's local path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc8facc-50f6-4beb-af17-e4d5cd6eace1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sku_dataset_folder  = # 'Path to directory where the images were downloaded'\n",
    "sku_dataset_folder  = '/Users/f0z01ld/Work/datasets/'\n",
    "sku_dataset_dirname = 'SKU110K_fixed'\n",
    "path_images         = Path(sku_dataset_folder) / sku_dataset_dirname / 'images'\n",
    "path_annotations    = Path(sku_dataset_folder) / sku_dataset_dirname / 'annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62cc8b2-4164-424a-876e-b8cf187a6db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls $path_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b80d4f-94b2-4041-87ff-b12ed88da744",
   "metadata": {},
   "source": [
    "#### Re-organize files into test, train, and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da85e39-02bc-43a0-a88d-fb5fc089c742",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_to_channel = {\n",
    "    \"train\": \"train\",\n",
    "    \"val\": \"validation\",\n",
    "    \"test\": \"test\",\n",
    "}\n",
    "\n",
    "assert path_images.exists(), f\"{path_images} not found\"\n",
    "\n",
    "for channel_name in prefix_to_channel.values():\n",
    "    if not (path_images.parent / channel_name).exists():\n",
    "        (path_images.parent / channel_name).mkdir()\n",
    "\n",
    "for path_img in path_images.iterdir():\n",
    "    for prefix in prefix_to_channel:\n",
    "        if path_img.name.startswith(prefix):\n",
    "            path_img.replace(\n",
    "                path_images.parent / prefix_to_channel[prefix] / path_img.name\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6acbc1-1503-4d93-97c4-a0eab9526eef",
   "metadata": {},
   "source": [
    "#### Remove corrupted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33787bb-987a-4ae8-98d8-a42f7ab4f653",
   "metadata": {},
   "outputs": [],
   "source": [
    "CORRUPTED_IMAGES = {\n",
    "    \"train\": (\"train_4222.jpg\", \"train_5822.jpg\", \"train_882.jpg\", \"train_924.jpg\"),\n",
    "    \"validation\": tuple(),\n",
    "    \"test\": (\"test_274.jpg\", \"test_2924.jpg\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10df4e3-c45e-4246-b520-2ff00a9951bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel_name in prefix_to_channel.values():\n",
    "    for img_name in CORRUPTED_IMAGES[channel_name]:\n",
    "        try:\n",
    "            (path_images.parent / channel_name / img_name).unlink()\n",
    "            print(f\"{img_name} removed from channel {channel_name} \")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"{img_name} not in channel {channel_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dfce98-debb-464a-811a-f27c835a0f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected output:\n",
    "# Number of train images = 8215\n",
    "# Number of validation images = 588\n",
    "# Number of test images = 2934\n",
    "for channel_name in prefix_to_channel.values():\n",
    "    print(\n",
    "        f\"Number of {channel_name} images = {sum(1 for x in (path_images.parent / channel_name).glob('*.jpg'))}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce703c1-f3d0-40af-a1b8-07d8d15db22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rmdir(path_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b26ae8c-53bf-45f8-8e1e-3e20b0056b5a",
   "metadata": {},
   "source": [
    "#### Reformat label (annotations) data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d508224-7b71-4ad5-a9b6-3ab3d6027e3c",
   "metadata": {},
   "source": [
    "Taking the snipped of code from `./yolov5/data/SKU-110K.yaml` and modifying it for our use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdd8de1-385e-4725-8b3b-020bd0cb5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolov5_dataset_folder = os.getcwd()\n",
    "yolov5_sku_dataset_dirname = 'SKU110K_fixed'\n",
    "local_path_annotations = Path(yolov5_dataset_folder) / yolov5_sku_dataset_dirname / 'labels'\n",
    "local_path_images = Path(yolov5_dataset_folder) / yolov5_sku_dataset_dirname / 'images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664a2e80-f04b-4c0d-8ff2-bcc07548c3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_path_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25470a53-d9d2-4235-adf3-fd52ceea8f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $local_path_annotations $local_path_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582eaf2-1f75-4a2a-bdd7-f5afb379a355",
   "metadata": {},
   "source": [
    "The original format of the `SKU110K` dataset is:\n",
    "\n",
    "`'image', 'x1', 'y1', 'x2', 'y2', 'class', 'image_width', 'image_height'`\n",
    "\n",
    "We need to convert it to `YOLO` format, which is:\n",
    "\n",
    "`'class', 'x1', 'y1', 'x2', 'y2'`\n",
    "\n",
    "We also need to normalize the bounding box coordinates as expected by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbefb81-8296-47ce-9d38-b22b0af09728",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = 'image', 'x1', 'y1', 'x2', 'y2', 'class', 'image_width', 'image_height'\n",
    "annotation_files =  path_annotations.glob('*.csv')\n",
    "for file in annotation_files:\n",
    "    print(file)\n",
    "    data = pd.read_csv(file, names=names)  # annotations\n",
    "    prefix = file.name.split('_')[-1].replace('.csv','')\n",
    "    out_labels_dir = local_path_annotations / prefix\n",
    "    out_images_dir = local_path_images / prefix\n",
    "\n",
    "    isExist = os.path.exists(out_labels_dir)\n",
    "    if not isExist:\n",
    "        os.mkdir(out_labels_dir)\n",
    "\n",
    "    isExist = os.path.exists(out_images_dir)\n",
    "    if not isExist:\n",
    "        os.mkdir(out_images_dir)\n",
    "        \n",
    "    for filename_img in data['image'].unique():\n",
    "        # Get all bounding boxes for this image\n",
    "        mask_filename_img = data['image'] == filename_img\n",
    "        data_img = data[mask_filename_img].copy().reset_index()\n",
    "\n",
    "        # Reformat each bounding box and add it to output file\n",
    "        # YOLO format is normalized (img_width, img_height) = (1, 1)\n",
    "        width = data_img.image_width[0]\n",
    "        height = data_img.image_height[0]\n",
    "        data_img['x1'] = data_img['x1'] / width\n",
    "        data_img['y1'] = data_img['y1'] / height\n",
    "        data_img['x2'] = data_img['x2'] / width\n",
    "        data_img['y2'] = data_img['y2'] / height\n",
    "        data_img['class'] = 0\n",
    "        \n",
    "        data_img = data_img[['class','x1','y1','x2','y2']]\n",
    "\n",
    "        # Set up the necessary paths\n",
    "        filename_label = filename_img.replace('jpg','txt')\n",
    "        out_labels_file = out_labels_dir / filename_label\n",
    "        in_images_file = path_images.parent / prefix_to_channel[prefix] / filename_img\n",
    "        out_images_file = out_images_dir / filename_img\n",
    "\n",
    "        try:\n",
    "            _ = shutil.copy2(in_images_file, out_images_file)\n",
    "        except:\n",
    "            # Exceptions are due to image file not existing for the corresponding label\n",
    "            # raise NameError('check the image file name')\n",
    "            print(f'check the image file name {filename_img}') \n",
    "            continue\n",
    "\n",
    "        # If the image file is found and copied, it's safe to generate the corresponding label file\n",
    "        data_img.to_csv(out_labels_file , sep=' ', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed77d30-f19f-4076-a525-4bbffaa44b22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
